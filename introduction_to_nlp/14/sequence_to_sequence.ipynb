{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3f691e-c5a1-4acc-8d39-44ddd866ada6",
   "metadata": {},
   "source": [
    "## 1. 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8189fc-9d0a-418a-862b-aa70c855ed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 05:19:15.145971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 05:19:15.966727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-21 05:19:15.966867: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-21 05:19:15.966879: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# 패키지 불러오기\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241b110-fdac-48a9-a1c5-499cd977cb9a",
   "metadata": {},
   "source": [
    "### 데이터 다운로드\n",
    "\n",
    "url = \"http://www.manythings.org/anki/fra-eng.zip\"\n",
    "r = requests.get(url, headers = {\"User-Agent\": \"cglee\"})\n",
    "filename = url.split(\"/\")[- 1]\n",
    "\n",
    "with open(filename, \"wb\") as output_file:\n",
    "  output_file.write(r.content)\n",
    "  \n",
    "with zipfile.ZipFile(filename, \"r\") as zip:\n",
    "  zip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b21cb9-0455-4beb-a349-d590ed08bda5",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4e3a4e-0a97-4383-a212-a6c3f273d28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 개수 : 217975\n"
     ]
    }
   ],
   "source": [
    "lines = pd.read_csv(\"fra.txt\", names = [\"src\", \"tar\", \"lic\"], sep = \"\\t\")\n",
    "lines = lines.loc[:, \"src\":\"tar\"]\n",
    "\n",
    "print('전체 샘플의 개수 :',len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20fd6f1-c657-4280-b0fa-e71f76a98bd7",
   "metadata": {},
   "source": [
    "### 전체 샘플에서 최초 6만 개의 표본 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66ee5c2-4dc8-4479-af92-f7500bb3b5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19133</th>\n",
       "      <td>Finish the story.</td>\n",
       "      <td>Termine l'histoire.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11341</th>\n",
       "      <td>I want details.</td>\n",
       "      <td>Je souhaite avoir des détails.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43883</th>\n",
       "      <td>Why are you cursing?</td>\n",
       "      <td>Pourquoi jurez-vous ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20961</th>\n",
       "      <td>I'm very serious.</td>\n",
       "      <td>Je suis très sérieuse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50754</th>\n",
       "      <td>Tom wasn't born rich.</td>\n",
       "      <td>Tom n'est pas né riche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19092</th>\n",
       "      <td>Everybody's dead.</td>\n",
       "      <td>Tout le monde a crevé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18495</th>\n",
       "      <td>You're to blame.</td>\n",
       "      <td>Vous êtes responsables.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14438</th>\n",
       "      <td>Go to the store.</td>\n",
       "      <td>Va au magasin !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39776</th>\n",
       "      <td>I reviewed the file.</td>\n",
       "      <td>J'ai examiné le fichier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23856</th>\n",
       "      <td>You deserve that.</td>\n",
       "      <td>Vous le méritez.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         src                             tar\n",
       "19133      Finish the story.             Termine l'histoire.\n",
       "11341        I want details.  Je souhaite avoir des détails.\n",
       "43883   Why are you cursing?           Pourquoi jurez-vous ?\n",
       "20961      I'm very serious.          Je suis très sérieuse.\n",
       "50754  Tom wasn't born rich.         Tom n'est pas né riche.\n",
       "19092      Everybody's dead.          Tout le monde a crevé.\n",
       "18495       You're to blame.         Vous êtes responsables.\n",
       "14438       Go to the store.                 Va au magasin !\n",
       "39776   I reviewed the file.        J'ai examiné le fichier.\n",
       "23856      You deserve that.                Vous le méritez."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[0:60000]\n",
    "\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3aabe-f296-4860-ad62-203b94605ae1",
   "metadata": {},
   "source": [
    "### 번역 문장에 문장 시작 심볼 ‘\\t’, 종료 심볼 ‘\\n’ 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318f98c2-4650-43bf-9fc1-fecd939cdc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17109</th>\n",
       "      <td>This is so easy.</td>\n",
       "      <td>\\t C'est si facile. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39916</th>\n",
       "      <td>I took this picture.</td>\n",
       "      <td>\\t J'ai pris cette photo. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>I like R&amp;B.</td>\n",
       "      <td>\\t J'aime le R&amp;B. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26439</th>\n",
       "      <td>I truly loved her.</td>\n",
       "      <td>\\t Je l'aimais sincèrement. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19034</th>\n",
       "      <td>Don't pick it up.</td>\n",
       "      <td>\\t Ne le ramassez pas. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45852</th>\n",
       "      <td>He may well be right.</td>\n",
       "      <td>\\t Il pourrait bien avoir raison. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45569</th>\n",
       "      <td>Has Tom become crazy?</td>\n",
       "      <td>\\t Tom est-il devenu fou ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49813</th>\n",
       "      <td>There's no more salt.</td>\n",
       "      <td>\\t Il n'y a plus de sel. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>You can come.</td>\n",
       "      <td>\\t Vous pouvez venir. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9933</th>\n",
       "      <td>You're a star.</td>\n",
       "      <td>\\t Tu es une célébrité. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         src                                   tar\n",
       "17109       This is so easy.                \\t C'est si facile. \\n\n",
       "39916   I took this picture.          \\t J'ai pris cette photo. \\n\n",
       "2030             I like R&B.                  \\t J'aime le R&B. \\n\n",
       "26439     I truly loved her.        \\t Je l'aimais sincèrement. \\n\n",
       "19034      Don't pick it up.             \\t Ne le ramassez pas. \\n\n",
       "45852  He may well be right.  \\t Il pourrait bien avoir raison. \\n\n",
       "45569  Has Tom become crazy?         \\t Tom est-il devenu fou ? \\n\n",
       "49813  There's no more salt.           \\t Il n'y a plus de sel. \\n\n",
       "6705           You can come.              \\t Vous pouvez venir. \\n\n",
       "9933          You're a star.            \\t Tu es une célébrité. \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x: \"\\t \" + x + \" \\n\")\n",
    "\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec079f-e846-4354-8c5f-61d37e621bc8",
   "metadata": {},
   "source": [
    "문자 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "452c2694-70d4-477a-88f6-18bf45e92644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 char 집합:  80\n",
      "target 문장의 char 집합:  103\n"
     ]
    }
   ],
   "source": [
    "src_vocab = set()\n",
    "for line in lines.src:\n",
    "  for char in line:\n",
    "    src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "  for char in line:\n",
    "    tar_vocab.add(char)\n",
    "\n",
    "src_vocab_size = len(src_vocab) + 1\n",
    "tar_vocab_size = len(tar_vocab) + 1\n",
    "\n",
    "print(\"source 문장의 char 집합: \", src_vocab_size)\n",
    "print(\"target 문장의 char 집합: \", tar_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b054662c-827a-48d0-b507-937ec2858799",
   "metadata": {},
   "source": [
    "### 문자 튜플을 리스트로 변환, 정렬, 인덱스 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16355d48-c3f7-4a12-8da2-503c415d862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '°': 76, 'é': 77, '’': 78, '€': 79}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, '\\u2009': 99, '‘': 100, '’': 101, '\\u202f': 102}\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "src_to_index = dict([(word, i + 1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i + 1) for i, word in enumerate(tar_vocab)])\n",
    "\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0243130b-8724-4fc9-be9d-833ec3348a7d",
   "metadata": {},
   "source": [
    "### 인코더 입력 데이터 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6ac93d-b9c3-42ac-a6c0-bc670d4c5411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더 입력 데이터 정수 인코딩 결과:  [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "\n",
    "for line in lines.src:\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        encoded_line.append(src_to_index[char])\n",
    "    encoder_input.append(encoded_line)\n",
    "\n",
    "print(\"인코더 입력 데이터 정수 인코딩 결과: \", encoder_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ca464-08ed-4b82-9678-e88e7073c866",
   "metadata": {},
   "source": [
    "### 디코더 입력 데이터 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51602586-c600-4373-9f42-c9bd53d1bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코더 입력 데이터 정수 인코딩 결과:  [[1, 3, 48, 52, 3, 4, 3, 2], [1, 3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [1, 3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [1, 3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [1, 3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "\n",
    "for line in lines.tar:\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        encoded_line.append(tar_to_index[char])\n",
    "    decoder_input.append(encoded_line)\n",
    "\n",
    "print(\"디코더 입력 데이터 정수 인코딩 결과: \", decoder_input[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3bd55a-89cd-4b78-900c-f566411ba210",
   "metadata": {},
   "source": [
    "### 정답 데이터 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62fd8cc6-1196-44b7-a87b-930224013470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 데이터 정수 인코딩 결과:  [[3, 48, 52, 3, 4, 3, 2], [3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "\n",
    "for line in lines.tar:\n",
    "    timestep = 0\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        # 시점이 0을 초과하는 경우 문자를 인덱스로 변환하여 저장하고,\n",
    "        # 시점이 0인 경우 통과합니다.\n",
    "        if timestep > 0:\n",
    "            encoded_line.append(tar_to_index[char])\n",
    "        timestep += 1\n",
    "    decoder_target.append(encoded_line)\n",
    "\n",
    "print(\"정답 데이터 정수 인코딩 결과: \", decoder_target[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9949d98-4c0b-48cd-8f6c-4b9b59b4b667",
   "metadata": {},
   "source": [
    "### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "977a5e01-478c-467f-b2c2-c239ffe128bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 최대 길이:  22\n",
      "Target 최대 길이:  76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "\n",
    "print(\"Source 최대 길이: \", max_src_len)\n",
    "print(\"Target 최대 길이: \", max_tar_len)\n",
    "\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_src_len, padding = \"post\", dtype = object)\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_tar_len, padding = \"post\", dtype = object)\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_tar_len, padding = \"post\", dtype = object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed4081-5624-4568-8874-4696f795363c",
   "metadata": {},
   "source": [
    "### 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74dfe694-7094-41cf-a993-f019b0f8a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13ea01-53c4-4c51-a54a-3d64f58fb1a3",
   "metadata": {},
   "source": [
    "## 2. 번역기 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc858f-fecc-43a9-b749-438b065a5992",
   "metadata": {},
   "source": [
    "### 인코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df26b03b-672d-4c7b-96cb-0fd5595a00bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 05:19:22.461810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-21 05:19:22.472786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-21 05:19:22.474428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-21 05:19:22.476927: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 05:19:22.478161: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-21 05:19:22.479809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-21 05:19:22.481413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-21 05:19:23.228051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-21 05:19:23.229862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-21 05:19:23.231387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-21 05:19:23.232840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13582 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "encoder_inputs = Input(shape = (None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units = 256, return_state = True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5dc55-7113-4e2a-9ae5-ce9aaaa3ce2e",
   "metadata": {},
   "source": [
    "### 디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d9491f3-a2a0-4d9c-b6b2-0a8f886ed16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape = (None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state = True)\n",
    "\n",
    "## 디코더에게 인코더의 상태 전달\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation = \"softmax\")\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model(\n",
    "    inputs = [encoder_inputs, decoder_inputs],\n",
    "    outputs = decoder_outputs\n",
    ")\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131cb8e5-ff68-40f3-bbe9-499d571cc5ea",
   "metadata": {},
   "source": [
    "### 번역기 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df39d405-79e0-4693-a5af-2b0bd03c4eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 05:19:30.073158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n",
      "2023-04-21 05:19:30.977484: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f55d00cc2e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-21 05:19:30.977531: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2023-04-21 05:19:30.983811: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-21 05:19:31.110094: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 16s 15ms/step - loss: 0.8537 - val_loss: 0.7779\n",
      "Epoch 2/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.5724 - val_loss: 0.6671\n",
      "Epoch 3/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.5010 - val_loss: 0.5981\n",
      "Epoch 4/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.4541 - val_loss: 0.5546\n",
      "Epoch 5/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.4191 - val_loss: 0.5148\n",
      "Epoch 6/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3920 - val_loss: 0.4880\n",
      "Epoch 7/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3714 - val_loss: 0.4705\n",
      "Epoch 8/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3550 - val_loss: 0.4538\n",
      "Epoch 9/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3415 - val_loss: 0.4386\n",
      "Epoch 10/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3298 - val_loss: 0.4273\n",
      "Epoch 11/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3196 - val_loss: 0.4181\n",
      "Epoch 12/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3106 - val_loss: 0.4102\n",
      "Epoch 13/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3026 - val_loss: 0.4039\n",
      "Epoch 14/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2954 - val_loss: 0.3970\n",
      "Epoch 15/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2889 - val_loss: 0.3912\n",
      "Epoch 16/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2831 - val_loss: 0.3885\n",
      "Epoch 17/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2774 - val_loss: 0.3821\n",
      "Epoch 18/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2725 - val_loss: 0.3789\n",
      "Epoch 19/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2678 - val_loss: 0.3735\n",
      "Epoch 20/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2633 - val_loss: 0.3700\n",
      "Epoch 21/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2591 - val_loss: 0.3710\n",
      "Epoch 22/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2551 - val_loss: 0.3646\n",
      "Epoch 23/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2516 - val_loss: 0.3636\n",
      "Epoch 24/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2479 - val_loss: 0.3627\n",
      "Epoch 25/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2446 - val_loss: 0.3601\n",
      "Epoch 26/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2414 - val_loss: 0.3582\n",
      "Epoch 27/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2382 - val_loss: 0.3580\n",
      "Epoch 28/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2353 - val_loss: 0.3541\n",
      "Epoch 29/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2325 - val_loss: 0.3527\n",
      "Epoch 30/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2297 - val_loss: 0.3520\n",
      "Epoch 31/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2271 - val_loss: 0.3531\n",
      "Epoch 32/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2246 - val_loss: 0.3507\n",
      "Epoch 33/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2220 - val_loss: 0.3494\n",
      "Epoch 34/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2197 - val_loss: 0.3492\n",
      "Epoch 35/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2173 - val_loss: 0.3502\n",
      "Epoch 36/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2150 - val_loss: 0.3489\n",
      "Epoch 37/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2128 - val_loss: 0.3493\n",
      "Epoch 38/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2108 - val_loss: 0.3481\n",
      "Epoch 39/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2085 - val_loss: 0.3503\n",
      "Epoch 40/40\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.2064 - val_loss: 0.3491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f577fbce9d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = [encoder_input, decoder_input],\n",
    "    y = decoder_target,\n",
    "    batch_size = 64,\n",
    "    epochs = 40,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d734690-ff18-4279-a1a5-a5dd6a394d29",
   "metadata": {},
   "source": [
    "## 3. 번역기 실행\n",
    "\n",
    "### 인코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9a3daca-a18c-4acc-97e5-67ea85ac2c27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(\n",
    "    inputs = encoder_inputs,\n",
    "    outputs = encoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642f920-7c12-482e-87e4-2c2f46db36de",
   "metadata": {},
   "source": [
    "### 디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2818c166-fda7-4086-b0d3-68dfd54a4776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape = (256, ))\n",
    "decoder_state_input_c = Input(shape = (256, ))\n",
    "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs,\n",
    "    initial_state = decoder_state_inputs\n",
    ")\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    inputs = [decoder_inputs] + decoder_state_inputs,\n",
    "    outputs = [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f54f6-b6c0-4810-83ca-6bdb1404a5ed",
   "metadata": {},
   "source": [
    "### 인덱스를 단어로 변환하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d510c6d5-6e68-4861-a7fb-f29a5f948084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6092d9-fa9f-481b-b9f1-88a657ec6be7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 변역을 수행하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7092e19e-5345-495b-9b08-0ac05dc8e779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_sequence(input_seq):\n",
    "    # 인코더에 입력 시퀀스를 입력하여 상태값을 얻습니다\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # (3차원 크기, 행 크기, 열 크기)\n",
    "    # (1, 1, 103)\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index[\"\\t\"]] = 1\n",
    "\n",
    "    stop_condition = False\n",
    "    translated_sentence = \"\"\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens)\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        translated_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == \"\\n\" or\n",
    "            len(translated_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return translated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c03160e-43a3-464d-91a8-6d261f4208c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 479ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "------------------------------\n",
      "입력 문장:  Go.\n",
      "정답 문장:  \t En route ! \n",
      "\n",
      "번역 문장:  Décampe ! \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "------------------------------\n",
      "입력 문장:  Hi.\n",
      "정답 문장:  \t Salut ! \n",
      "\n",
      "번역 문장:  Fais-le ! \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "------------------------------\n",
      "입력 문장:  Run!\n",
      "정답 문장:  \t Prenez vos jambes à vos cous ! \n",
      "\n",
      "번역 문장:  Cours ! \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "------------------------------\n",
      "입력 문장:  Run.\n",
      "정답 문장:  \t Prenez vos jambes à vos cous ! \n",
      "\n",
      "번역 문장:  Courrez ! \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "------------------------------\n",
      "입력 문장:  Hide.\n",
      "정답 문장:  \t Cachez-vous. \n",
      "\n",
      "번역 문장:  Cale ! \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "------------------------------\n",
      "입력 문장:  Relax.\n",
      "정답 문장:  \t Détends-toi ! \n",
      "\n",
      "번역 문장:  Commence à l'aide. \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "------------------------------\n",
      "입력 문장:  No way!\n",
      "정답 문장:  \t C'est pas possible ! \n",
      "\n",
      "번역 문장:  Aucun ! \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "------------------------------\n",
      "입력 문장:  Get out.\n",
      "정답 문장:  \t Sortez ! \n",
      "\n",
      "번역 문장:  Décampe ! \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "------------------------------\n",
      "입력 문장:  Get away!\n",
      "정답 문장:  \t Déguerpissez. \n",
      "\n",
      "번역 문장:  Décampe ! \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "------------------------------\n",
      "입력 문장:  Hold this.\n",
      "정답 문장:  \t Tenez ceci ! \n",
      "\n",
      "번역 문장:  Faites attention. \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
    "    input_seq = encoder_input[[seq_index]]\n",
    "    translated_sentence = translate_sequence(input_seq)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"입력 문장: \", lines.src[seq_index])\n",
    "    print(\"정답 문장: \", lines.tar[seq_index])\n",
    "    # 문장 종료 심볼 '\\n'을 제외하고 출력\n",
    "    print(\"번역 문장: \", translated_sentence[1:len(translated_sentence) - 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
