{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I like programming.', response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 41, 'total_tokens': 45}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': 'fp_f38f4d6482', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"다음 문장을 한국어에서 영어로 번역하라: 저는 프로그래밍을 좋아합니다.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='제가 마지막으로 말한 것은 \"제가 마지막으로 말한 것은\"입니다. 하지만 이것은 당신이 무엇을 물어보려고 했는지에 대한 직접적인 대답이 아닐 수 있습니다. 구체적인 질문이나 주제에 대해 더 자세히 알려주시면, 더 도움이 될 수 있는 정보를 제공해 드리겠습니다.', response_metadata={'token_usage': {'completion_tokens': 131, 'prompt_tokens': 22, 'total_tokens': 153}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': 'fp_f38f4d6482', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "    HumanMessage(content=\"방금 뭐라고 말했어?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said, \"I like programming.\"', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 68, 'total_tokens': 76}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': 'fp_f38f4d6482', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"다음 문장을 한국어에서 영어로 번역하라: 저는 프로그래밍을 좋아합니다.\"),\n",
    "        AIMessage(content=\"I like programming.\"),\n",
    "        HumanMessage(content=\"방금 뭐라고 말했어?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said, \"I like programming.\"', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 88, 'total_tokens': 96}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': 'fp_f38f4d6482', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"다음 문장을 한국어에서 영어로 번역하라: 저는 프로그래밍을 좋아합니다.\"\n",
    "            ),\n",
    "            AIMessage(content=\"I like programming.\"),\n",
    "            HumanMessage(content=\"방금 뭐라고 말했어?\"),\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕!'), AIMessage(content='잘 지냈어?')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "demo_ephemeral_chat_history = ChatMessageHistory()\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"안녕!\")\n",
    "\n",
    "demo_ephemeral_chat_history.add_ai_message(\"잘 지냈어?\")\n",
    "\n",
    "demo_ephemeral_chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I like programming.', response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 82, 'total_tokens': 86}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': 'fp_f38f4d6482', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\"다음 문장을 한국어에서 영어로 번역하라: 저는 프로그래밍을 좋아합니다.\")\n",
    "\n",
    "response = chain.invoke({\"messages\": demo_ephemeral_chat_history.messages})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I said, \"I like programming.\"', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 109, 'total_tokens': 117}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': 'fp_a7daf7c51e', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.add_ai_message(response)\n",
    "\n",
    "demo_ephemeral_chat_history.add_user_message(\"방금 뭐라고 말했어?\")\n",
    "\n",
    "chain.invoke({\"messages\": demo_ephemeral_chat_history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕!'),\n",
       " AIMessage(content='잘 지냈어?'),\n",
       " HumanMessage(content='다음 문장을 한국어에서 영어로 번역하라: 저는 프로그래밍을 좋아합니다.'),\n",
       " AIMessage(content='I like programming.', response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 82, 'total_tokens': 86}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': 'fp_f38f4d6482', 'finish_reason': 'stop', 'logprobs': None}),\n",
       " HumanMessage(content='방금 뭐라고 말했어?')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
